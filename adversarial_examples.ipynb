{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import tqdm\n",
    "from collections import namedtuple\n",
    "from scipy.optimize import Bounds, minimize\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "from torch.functional import F \n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of adversarial models that we will create. The first is a non-specific misclassification and the second is a targeted misclassification. Lastly we will test the cross-model susceptibility.\n",
    "\n",
    "The following cell is group of helper functions including two that train and test non-adversarial models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_dataset(torchvision_dataset):\n",
    "    save_dir = \"./mnist\"\n",
    "    transform_list = [transforms.ToTensor()]\n",
    "    transform = transforms.Compose(transform_list)\n",
    "    kwargs = {\n",
    "        \"download\": True,\n",
    "        \"transform\": transform,\n",
    "    }\n",
    "    train = torchvision_dataset(save_dir, train=True, **kwargs)\n",
    "    test = torchvision_dataset(save_dir, train=False, **kwargs)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def resize_dataset(dataset, dataset_len=None):\n",
    "    if dataset_len is None:\n",
    "        return dataset\n",
    "    assert 0 <= dataset_len <= len(dataset)\n",
    "    ignored_len = len(dataset) - dataset_len\n",
    "    sizes = (dataset_len, ignored_len)\n",
    "    dataset, ignored = random_split(dataset, sizes)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_batches(train, test, batch_size=100):\n",
    "    assert 1 <= batch_size <= len(test)\n",
    "    kwargs = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"shuffle\": True,\n",
    "    }\n",
    "    train_loader = DataLoader(train, **kwargs)\n",
    "    test_loader = DataLoader(test, **kwargs)\n",
    "    return train_loader, test_loader\n",
    "    \n",
    "def train_model(model, device, train_loader, optimizer, criterion, num_epochs=1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Training Epoch\", epoch)\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def test_model(model, device, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, targets) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Prediction\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our convolutional network that we use to train both our adversarial and non-adversarial models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Net(nn.Module):\n",
    "    def __init__(self, in_height, in_width, num_targets):\n",
    "        super().__init__()\n",
    "        # Convolutional parameters\n",
    "        kernel_size = 4\n",
    "        stride = 1\n",
    "\n",
    "        # Pool layer and its parameters\n",
    "        pool_kernel_size = 2\n",
    "        pool_stride = pool_kernel_size # When these values are the same it reduces the image by half\n",
    "        self.pool = nn.MaxPool2d(pool_kernel_size, pool_stride)\n",
    "\n",
    "        in_channels_2 = 1\n",
    "        out_channels_2 = 10\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels_2,\n",
    "            out_channels_2, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels_2)\n",
    "\n",
    "        self.conv2_height = height - kernel_size + 1\n",
    "        self.conv2_width = width - kernel_size + 1\n",
    "        self.conv2_size = self.conv2_height * self.conv2_width * out_channels_2\n",
    "\n",
    "        self.pool1_height = int(self.conv2_height / pool_kernel_size)\n",
    "        self.pool1_width = int(self.conv2_height / pool_kernel_size)\n",
    "        self.pool1_size = self.pool1_height * self.pool1_width * out_channels_2\n",
    "\n",
    "        out_channels_3 = 10\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            out_channels_2, \n",
    "            out_channels_3, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels_3)\n",
    "\n",
    "        self.conv3_height = self.pool1_height - kernel_size + 1\n",
    "        self.conv3_width = self.pool1_width - kernel_size + 1\n",
    "        self.conv3_size = self.conv3_height * self.conv3_width * out_channels_3\n",
    "\n",
    "        self.pool2_height = int(self.conv3_height / pool_kernel_size)\n",
    "        self.pool2_width = int(self.conv3_height / pool_kernel_size)\n",
    "        self.pool2_size = self.pool2_height * self.pool2_width * out_channels_2\n",
    "\n",
    "        in_features_4 = self.pool2_size\n",
    "        out_features_4 = int(in_features_4 / 2)\n",
    "        self.fc1 = nn.Linear(in_features_4, out_features_4)\n",
    "        self.bn4 = nn.BatchNorm1d(out_features_4)\n",
    "\n",
    "        out_features_5 = int(out_features_4 / 2)\n",
    "        self.fc2 = nn.Linear(out_features_4, out_features_5)\n",
    "        self.bn5 = nn.BatchNorm1d(out_features_5)\n",
    "\n",
    "        self.fc3 = nn.Linear(out_features_5, num_targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolution and pooling\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # Second convolution and pooling\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        # Flattening convolutional layer for fully connected layer\n",
    "        batch_size = -1\n",
    "        x = x.view(batch_size, self.pool2_size) # This value was calculated in __init__\n",
    "\n",
    "        # First fcl\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn4(x)\n",
    "\n",
    "        # Second fcl\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn5(x)\n",
    "       \n",
    "        # Output fcl\n",
    "        x = self.fc3(x)   \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of our non-adversarial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "torchvision_dataset = datasets.MNIST\n",
    "train, test = load_dataset(torchvision_dataset)\n",
    "\n",
    "# Find dimensions\n",
    "height, width = train.data[0].shape\n",
    "num_targets = len(set(train.targets.numpy()))\n",
    "\n",
    "# Setting the size to \"None\" will use all instances\n",
    "train_len, test_len = 8000, 2000\n",
    "train = resize_dataset(train, train_len)\n",
    "test = resize_dataset(test, test_len)\n",
    "\n",
    "# Batch\n",
    "batch_size = 100\n",
    "train_loader, test_loader = make_batches(train, test, batch_size)\n",
    "\n",
    "# Make model\n",
    "good_model = Conv_Net(height, width, num_targets).to(device)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(good_model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "num_epochs = 1\n",
    "train_model(good_model, device, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "# Test\n",
    "accuracy = test_model(good_model, device, test_loader)\n",
    "print(f\"Original Accuracy: {accuracy} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in creating an adversarial network is to set its parameters. For that we will create a list of epsilon values. Each epsilon will be multiplied by a gradient designed to push the input into a blind spot. We want the first epsilon to be 0 so we can see examples where no perturbation is added to the input. \n",
    "\n",
    "Q: What is a reasonable max value for epsilon and why?\n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# This is the length of the epsilon_list you are going to create. If your list is longer or shorter you must reflect that change in this variable.\n",
    "num_epsilons = 5 \n",
    "\n",
    "# Make a list of epsilon values for the attack\n",
    "epsilon_list = ?\n",
    "\n",
    "# This is storage for samples from our adversarial model.\n",
    "examples = {\n",
    "    epsilon: {\n",
    "        \"original_images\": [],\n",
    "        \"adversarial_images\": [],\n",
    "        \"original_predictions\": [],\n",
    "        \"adversarial_predictions\": []\n",
    "    }\n",
    "    for epsilon in epsilon_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What is the purpose of the line \"images.requires_grad = True\"? \n",
    "\n",
    "A:\n",
    "\n",
    "Q: Below you will set the clamp min and max values on the line \"torch.clamp(perturbated_images, clamp_min, clamp_max)\". Why do we need to clamp and what would the effect of using a value outside the range be?\n",
    "\n",
    "A:\n",
    "    \n",
    "Q: This is very subtle. Why are we adding our perturbations instead of subtracting them? The goal should be to go in the opposite direction of the gradient. How is addition moving us uphill?\n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epsilon in epsilon_list:\n",
    "    print(f\"Epsilon: {epsilon}\")\n",
    "    \n",
    "    # Train Attack model\n",
    "    attack_model = Conv_Net(height, width, num_targets).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(attack_model.parameters(), lr = learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_model(attack_model, device, train_loader, optimizer, criterion, num_epochs)\n",
    "    pre_attack_accuracy = test_model(attack_model, device, test_loader)\n",
    "    print(f\"Pre-attack Accuracy: {pre_attack_accuracy} %\")\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sample = True \n",
    "    \n",
    "    for i, (images, targets) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        # Enable finding gradient w.r.t the inputs.\n",
    "        images.requires_grad = True \n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = attack_model(images)\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        image_grad = images.grad \n",
    "\n",
    "        grad_sign = image_grad.sign()\n",
    "        perturbation = ?\n",
    "        perturbed_images = ?\n",
    "        clamp_min = ?\n",
    "        clamp_max = ?\n",
    "        perturbed_images = torch.clamp(perturbed_images, clamp_min, clamp_max)\n",
    "\n",
    "        attack_output = attack_model(perturbed_images)\n",
    "        attack_predicted = torch.argmax(attack_output, 1)\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += (attack_predicted == targets).sum().item()\n",
    "        \n",
    "        if sample:\n",
    "            sample = False\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                examples[epsilon][\"original_images\"] = images.cpu().numpy()[:num_epsilons]\n",
    "                examples[epsilon][\"adversarial_images\"] = perturbed_images.cpu().numpy()[:num_epsilons]\n",
    "                examples[epsilon][\"original_predictions\"] = predicted.cpu().numpy()[:num_epsilons]\n",
    "                examples[epsilon][\"adversarial_predictions\"] = attack_predicted.cpu().numpy()[:num_epsilons]\n",
    "            \n",
    "        \n",
    "    post_attack_accuracy = correct / total\n",
    "    print(f\"Post-attack Accuracy: {post_attack_accuracy} %\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Please explain the figure including the images themselves, and their axes.\n",
    "\n",
    "A:\n",
    "\n",
    "Q: How effective was this adversarial model? \n",
    "\n",
    "A:\n",
    "\n",
    "Q: If you were a real attacker that relied on misclassification, how would you deal with the cases where the class was retained?\n",
    "\n",
    "A:\n",
    "\n",
    "Q: Go back and look at where we set grad_sign. If we had multiplied the gradient instead of the gradient sign by the epsilon value our performance would not be as high. Why?\n",
    "\n",
    "A:\n",
    "\n",
    "Q: Our purturbations depended on the gradient of the image. Why is the gradient necessary as opposed to some non-gradient dependent function the input image?\n",
    "\n",
    "A:\n",
    "\n",
    "Q: You can misclassify an image by just mutating it. What is the point of this model? \n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dim = 10, 12\n",
    "plt.figure(figsize=plot_dim)\n",
    "\n",
    "plot_index = 1\n",
    "for row in range(num_epsilons):\n",
    "    for column in range(num_epsilons):\n",
    "        plt.subplot(num_epsilons, num_epsilons, plot_index)\n",
    "\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "\n",
    "        epsilon = epsilon_list[row]\n",
    "        if column == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilon), fontsize=14)\n",
    "\n",
    "        adversarial_image = examples[epsilon][\"adversarial_images\"][column].squeeze()\n",
    "        original_prediction = examples[epsilon][\"original_predictions\"][column].item()\n",
    "        adversarial_prediction = examples[epsilon][\"adversarial_predictions\"][column].item()\n",
    "\n",
    "        plt.title(\"{} -> {}\".format(original_prediction, adversarial_prediction))\n",
    "        plt.imshow(adversarial_image, cmap=\"gray\")\n",
    "\n",
    "        plot_index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The last task is to plot just the purturbations. You can modify the code from the cell above but put the plotting code in this cell so that both copies are retained.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = namedtuple(\n",
    "    \"Config\",\n",
    "    (\n",
    "        \"batch_size\",\n",
    "        \"epochs\",\n",
    "        \"lr\",\n",
    "        \"lr_gamma\",\n",
    "        \"input_size\",\n",
    "        \"output_size\",\n",
    "        \"w_decay\",\n",
    "        \"r_weight\",\n",
    "        \"device\",\n",
    "    )\n",
    ")\n",
    "\n",
    "config = Config(\n",
    "    batch_size=64,\n",
    "    epochs=25,\n",
    "    lr=1e-4,\n",
    "    lr_gamma=0.88,\n",
    "    input_size=28*28,\n",
    "    output_size=10,\n",
    "    w_decay=1e-4,\n",
    "    r_weight=0.15,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "# MNIST Datasets\n",
    "train_ds = tv.datasets.MNIST(\n",
    "    \"./data\",\n",
    "    transform=tv.transforms.ToTensor(),\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "test_ds = tv.datasets.MNIST(\n",
    "    \"./data\",\n",
    "    transform=tv.transforms.ToTensor(),\n",
    "    train=False,\n",
    ")\n",
    "# MNIST Data Loaders\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config.batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_label(logits):\n",
    "    return torch.softmax(logits, 1).argmax(1)\n",
    "\n",
    "\n",
    "class FCNet100(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FCNet100, self).__init__()\n",
    "        self.config = config\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(config.input_size, 100),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Linear(100, 100),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Linear(100, config.output_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x).to(self.config.device)\n",
    "        x = x.view(x.size(0), self.config.input_size)\n",
    "        # Logits\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, loss_func, loader, config, epoch):\n",
    "    it = tqdm.tqdm(loader, ncols=80, desc=f\"train: {epoch + 1}/{config.epochs}\")\n",
    "    for imgs, targets in it:\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        imgs = imgs.to(config.device).double()\n",
    "        targets = targets.to(config.device)\n",
    "        out = model(imgs)\n",
    "        loss = loss_func(out, targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        \n",
    "def test(model, loader, config):\n",
    "    correct = 0\n",
    "    for imgs, targets in tqdm.tqdm(loader, ncols=80, desc=\"Test\"):\n",
    "        model.eval()\n",
    "        imgs = imgs.to(config.device).double()\n",
    "        targets = targets.to(config.device)\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs)\n",
    "            pred = logits_to_label(out)\n",
    "            correct += (pred == targets).sum()\n",
    "    N = len(loader.dataset)\n",
    "    acc = float(correct) / N\n",
    "    print(f\"Test acc: {acc:.02%}\")\n",
    "\n",
    "    \n",
    "def fetch_trained_model(model_class, train_loader, test_loader, load_from_file, path, config):\n",
    "    \"\"\"Either fetch a stored model from disc or train one from scratch\"\"\"\n",
    "    model = model_class(config).double().to(config.device)\n",
    "    if os.path.isfile(path) and load_from_file:\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        test(model, test_loader, config)\n",
    "    else:\n",
    "        opt = torch.optim.Adam(model.parameters(), config.lr, weight_decay=config.w_decay)\n",
    "        # Learning rate adjuster\n",
    "        sched = torch.optim.lr_scheduler.StepLR(opt, 1, config.lr_gamma)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for ep in range(config.epochs):\n",
    "            train(model, opt, criterion, train_loader, config, ep)\n",
    "            test(model, test_loader, config)\n",
    "            sched.step()\n",
    "        torch.save(model.state_dict(), path)\n",
    "    model.eval()\n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = fetch_trained_model(\n",
    "    FCNet100,\n",
    "    train_dl,\n",
    "    test_dl,\n",
    "    True,\n",
    "    \"./data/model_1.pt\",\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_penalty_func(xr, *args):\n",
    "    \"\"\"This is simply the equation from Section 4.1\"\"\"\n",
    "    x, net, c, target, device = args\n",
    "    # |r| penalty portion\n",
    "    size_penalty = c * np.abs(x - xr).sum()\n",
    "    # x + r as a tensor\n",
    "    xrt = torch.tensor(xr.reshape(1, 28, 28)).to(device)\n",
    "    # loss_f(x + r, l) penalty\n",
    "    logits = net(xrt)\n",
    "    class_penalty = nn.functional.cross_entropy(logits, target).item()\n",
    "    return size_penalty + class_penalty\n",
    "\n",
    "\n",
    "def find_adversarial_example(net, x, target, config):\n",
    "    \"\"\"This is the optimization problem described in Section 4.1\"\"\"\n",
    "    # The c weight for the L1 norm of r\n",
    "    c = config.r_weight\n",
    "    # Box constraint: [0, 1]^m\n",
    "    box_constraint = Bounds(np.zeros_like(x.ravel()), np.ones_like(x.ravel()))\n",
    "    # Target label\n",
    "    target = torch.tensor([target]).to(config.device, dtype=torch.int64)\n",
    "    # Args in addition to the (x + r) array that are used by the penalty function\n",
    "    args = (x.flatten(), net, c, target, device)\n",
    "    # Use x as initial guess for (x + r)\n",
    "    xr0 = x.copy()\n",
    "    with torch.no_grad():\n",
    "        res = minimize(\n",
    "            adv_penalty_func,\n",
    "            # Flatten it since minimize only works on a 1D array\n",
    "            xr0.flatten(),\n",
    "            args,\n",
    "            method='L-BFGS-B',\n",
    "            jac=None,\n",
    "            bounds=box_constraint,\n",
    "            tol=None,\n",
    "            callback=None,\n",
    "            options={\n",
    "                'disp': None,\n",
    "                'maxcor': 10,\n",
    "                'ftol': 2.220446049250313e-09,\n",
    "                'gtol': 1e-05,\n",
    "                'eps': 1e-9,\n",
    "                'maxfun': 45000,\n",
    "                'maxiter': 45000,\n",
    "                'iprint': -1,\n",
    "                'maxls': 30\n",
    "            }\n",
    "        )\n",
    "    # Reshape back into an image\n",
    "    xr = torch.tensor(res.x.reshape(x.shape))\n",
    "    return xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select N images that the model correctly classifies already\n",
    "N = 16\n",
    "adv_target = 8\n",
    "x_imgs = []\n",
    "x_labels = []\n",
    "for x, label in test_ds:\n",
    "    if label == adv_target:\n",
    "        continue\n",
    "    x = x.to(config.device).double()\n",
    "    if (logits_to_label(model(x)) == label).item():\n",
    "        # Make sure that the model correctly classifies this x\n",
    "        x_imgs.append(x.cpu())\n",
    "        x_labels.append(label)\n",
    "    if len(x_imgs) >= N:\n",
    "        break\n",
    "x_labels = np.array(x_labels).reshape(4, 4)\n",
    "grid = tv.utils.make_grid(x_imgs, nrow=4, pad_value=1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Originals\")\n",
    "plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "print(x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_imgs = []\n",
    "xr_labels = []\n",
    "for x in tqdm.tqdm(x_imgs, ncols=80):\n",
    "    xr = find_adversarial_example(model, x.numpy(), adv_target, config)\n",
    "    xr_imgs.append(xr)\n",
    "    new_label = logits_to_label(model(xr.to(config.device))).item()\n",
    "    xr_labels.append(new_label)\n",
    "xr_labels = np.array(xr_labels).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = tv.utils.make_grid(xr_imgs, nrow=4, pad_value=1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Adversarial Examples\")\n",
    "plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "print(f\"New Labels:\\n{xr_labels}\")\n",
    "\n",
    "# Calculate r = (x + r) - x and display them\n",
    "r_imgs = [xr - x for xr, x in zip(xr_imgs, x_imgs)]\n",
    "grid = tv.utils.make_grid(r_imgs, nrow=4, pad_value=1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Adversarial Perturbations\")\n",
    "plt.imshow(np.transpose(grid, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNet200(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FCNet200, self).__init__()\n",
    "        self.config = config\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(config.input_size, 200),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Linear(200, 200),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Linear(200, config.output_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x).to(self.config.device)\n",
    "        x = x.view(x.size(0), self.config.input_size)\n",
    "        # Logits\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2 = fetch_trained_model(\n",
    "    FCNet200,\n",
    "    train_dl,\n",
    "    test_dl,\n",
    "    True,\n",
    "    \"./data/model_2.pt\",\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_model_labels = []\n",
    "for xr in xr_imgs:\n",
    "    label = logits_to_label(model2(xr.unsqueeze(0).to(config.device))).item()\n",
    "    cross_model_labels.append(label)\n",
    "cross_model_labels = np.array(cross_model_labels).reshape(4, 4)\n",
    "print(f\"Cross Model Adverserial Predictions:\\n{cross_model_labels}\")\n",
    "print(f\"Attack Success: {(cross_model_labels == xr_labels).sum() / N:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
